{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmGPkskVAC4tHVdALMi9Ec",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SergeevnaVi/colab_/blob/main/%D0%98%D1%81%D1%82%D0%BE%D1%80%D0%B8%D1%8F_%D0%B8_%D1%80%D0%B0%D0%B7%D0%B2%D0%B8%D1%82%D0%B8%D0%B5_%D0%98%D0%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание"
      ],
      "metadata": {
        "id": "dJFGV3w22FSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ДЗ из первого файла"
      ],
      "metadata": {
        "id": "cEcB0Kl42Qho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Программно создадим персептрон, который будет выполнять логическую операцию ИЛИ\n",
        "\n"
      ],
      "metadata": {
        "id": "jGK99ZDv2ZSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Функция активации (ступенчатая)\n",
        "def activation_function(x):\n",
        "    return torch.tensor(1.0) if x >= 0 else torch.tensor(0.0)\n",
        "\n",
        "# Класс персептрона\n",
        "class Perceptron:\n",
        "    def __init__(self, num_inputs):\n",
        "        # Инициализация весов случайными значениями\n",
        "        self.weights = torch.rand(num_inputs, dtype=torch.float64)\n",
        "        self.bias = torch.rand(1, dtype=torch.float64)  # Инициализация смещения случайным значением\n",
        "\n",
        "    # Функция, вычисляющая выход персептрона\n",
        "    def feed_forward(self, inputs):\n",
        "        return activation_function(torch.sum(inputs * self.weights) + self.bias)\n",
        "\n",
        "    # Функция обучения персептрона\n",
        "    def train(self, inputs, target, learning_rate=0.1):\n",
        "        output = self.feed_forward(inputs)\n",
        "        error = target - output\n",
        "\n",
        "        # Вывод входов, выходов и ошибки\n",
        "        print(f\"Входы: {inputs.tolist()} Выход: {int(output)} Ошибка: {error}\")\n",
        "\n",
        "        # Обновление весов и смещения\n",
        "        self.weights += error * inputs * learning_rate\n",
        "        self.bias += error * learning_rate\n",
        "\n",
        "# Основная функция\n",
        "if __name__ == \"__main__\":\n",
        "    # Создание персептрона с двумя входами\n",
        "    perceptron = Perceptron(2)\n",
        "\n",
        "    # Обучающие данные\n",
        "    training_inputs = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float64)\n",
        "    training_outputs = torch.tensor([0, 1, 1, 1], dtype=torch.float64)  # Логическая операция OR\n",
        "\n",
        "    # Обучение персептрона\n",
        "    for _ in range(10):\n",
        "        for inputs, target in zip(training_inputs, training_outputs):\n",
        "            perceptron.train(inputs, target)\n",
        "\n",
        "    # Проверка обученного персептрона\n",
        "    for inputs, target in zip(training_inputs, training_outputs):\n",
        "        output = perceptron.feed_forward(inputs)\n",
        "        print(f\"Входы: {inputs.tolist()} Выход: {int(output)}\")"
      ],
      "metadata": {
        "id": "TChmEvv62miG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "2.   Обучите персептрон коньюкции (AND)\n",
        "\n"
      ],
      "metadata": {
        "id": "0UCK3UgB3MtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Функция активации (ступенчатая)\n",
        "def activation_function(x):\n",
        "    return torch.tensor(1.0) if x >= 0 else torch.tensor(0.0)\n",
        "\n",
        "# Класс персептрона\n",
        "class Perceptron:\n",
        "    def __init__(self, num_inputs):\n",
        "        # Инициализация весов случайными значениями\n",
        "        self.weights = torch.rand(num_inputs, dtype=torch.float64)\n",
        "        self.bias = torch.rand(1, dtype=torch.float64)  # Инициализация смещения случайным значением\n",
        "\n",
        "    # Функция, вычисляющая выход персептрона\n",
        "    def feed_forward(self, inputs):\n",
        "        return activation_function(torch.sum(inputs * self.weights) + self.bias)\n",
        "\n",
        "    # Функция обучения персептрона\n",
        "    def train(self, inputs, target, learning_rate=0.1):\n",
        "        output = self.feed_forward(inputs)\n",
        "        error = target - output\n",
        "\n",
        "        # Вывод входов, выходов и ошибки\n",
        "        print(f\"Входы: {inputs.tolist()} Выход: {int(output)} Ошибка: {error}\")\n",
        "\n",
        "        # Обновление весов и смещения\n",
        "        self.weights += error * inputs * learning_rate\n",
        "        self.bias += error * learning_rate\n",
        "\n",
        "# Основная функция\n",
        "if __name__ == \"__main__\":\n",
        "    # Создание персептрона с двумя входами\n",
        "    perceptron = Perceptron(2)\n",
        "\n",
        "    # Обучающие данные\n",
        "    training_inputs = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float64)\n",
        "    training_outputs = torch.tensor([0, 0, 0, 1], dtype=torch.float64)  # Логическая операция AND\n",
        "\n",
        "    # Обучение персептрона\n",
        "    for _ in range(10):\n",
        "        for inputs, target in zip(training_inputs, training_outputs):\n",
        "            perceptron.train(inputs, target)\n",
        "\n",
        "    # Проверка обученного персептрона\n",
        "    for inputs, target in zip(training_inputs, training_outputs):\n",
        "        output = perceptron.feed_forward(inputs)\n",
        "        print(f\"Входы: {inputs.tolist()} Выход: {int(output)}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LrcGyDm83V3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "3.   Обучите персептрон искл. дизъюнкции (XOR)\n",
        "\n"
      ],
      "metadata": {
        "id": "Q7XfJAlJ3pWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Данные для обучения\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([0, 1, 1, 0])  # Операция XOR\n",
        "\n",
        "# Создание и обучение MLP-классификатора\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(5,), activation='relu', max_iter=400, learning_rate_init=0.01, solver='adam')\n",
        "mlp.fit(X, y)\n",
        "\n",
        "# Тестирование\n",
        "for xi in X:\n",
        "    print(f\"{xi} -> {mlp.predict([xi])[0]}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Hz_Du0Iq31Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ДЗ из второго файла"
      ],
      "metadata": {
        "id": "9yOoi2GX_7r5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Код решения задачи XOR *многослойным персептроном*"
      ],
      "metadata": {
        "id": "kexVKsLCAFIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Данные для обучения (XOR)\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([0, 1, 1, 0])  # Операция XOR\n",
        "\n",
        "# Создание и обучение MLP-классификатора\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(5,), activation='relu', max_iter=5000, solver='adam')\n",
        "mlp.fit(X, y)\n",
        "\n",
        "# Тестирование\n",
        "for xi in X:\n",
        "    print(f\"{xi} -> {mlp.predict([xi])[0]}\")"
      ],
      "metadata": {
        "id": "Nxr_aAuHAavC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Код однослойного персептрона"
      ],
      "metadata": {
        "id": "fVUlAdw-ApVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. На 10 000 эпох"
      ],
      "metadata": {
        "id": "ggNMmBkvBBwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Функция активации (ступенчатая)\n",
        "def activation_function(x):\n",
        "    return torch.tensor(1.0) if x >= 0 else torch.tensor(0.0)\n",
        "\n",
        "# Класс персептрона\n",
        "class Perceptron:\n",
        "    def __init__(self, num_inputs):\n",
        "        # Инициализация весов случайными значениями\n",
        "        self.weights = torch.rand(num_inputs, dtype=torch.float64)\n",
        "        self.bias = torch.rand(1, dtype=torch.float64)  # Инициализация смещения случайным значением\n",
        "\n",
        "    # Функция, вычисляющая выход персептрона\n",
        "    def feed_forward(self, inputs):\n",
        "        return activation_function(torch.sum(inputs * self.weights) + self.bias)\n",
        "\n",
        "    # Функция обучения персептрона\n",
        "    def train(self, inputs, target, learning_rate=0.1):\n",
        "        output = self.feed_forward(inputs)\n",
        "        error = target - output\n",
        "\n",
        "        # Вывод входов, выходов и ошибки\n",
        "        print(f\"Входы: {inputs.tolist()} Выход: {int(output)} Ошибка: {error}\")\n",
        "\n",
        "        # Обновление весов и смещения\n",
        "        self.weights += error * inputs * learning_rate\n",
        "        self.bias += error * learning_rate\n",
        "\n",
        "# Основная функция\n",
        "if __name__ == \"__main__\":\n",
        "    # Создание персептрона с двумя входами\n",
        "    perceptron = Perceptron(2)\n",
        "\n",
        "    # Обучающие данные\n",
        "    training_inputs = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float64)\n",
        "    training_outputs = torch.tensor([0, 1, 1, 0], dtype=torch.float64)  # Логическая операция XOR\n",
        "\n",
        "    # Обучение персептрона\n",
        "    for _ in range(10000):\n",
        "        for inputs, target in zip(training_inputs, training_outputs):\n",
        "            perceptron.train(inputs, target)\n",
        "\n",
        "    # Проверка обученного персептрона\n",
        "    for inputs, target in zip(training_inputs, training_outputs):\n",
        "        output = perceptron.feed_forward(inputs)\n",
        "        print(f\"Входы: {inputs.tolist()} Выход: {int(output)}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OHBCIUgvAv8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. На 20 000 эпох"
      ],
      "metadata": {
        "id": "05olo0j1Chtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Функция активации (ступенчатая)\n",
        "def activation_function(x):\n",
        "    return torch.tensor(1.0) if x >= 0 else torch.tensor(0.0)\n",
        "\n",
        "# Класс персептрона\n",
        "class Perceptron:\n",
        "    def __init__(self, num_inputs):\n",
        "        # Инициализация весов случайными значениями\n",
        "        self.weights = torch.rand(num_inputs, dtype=torch.float64)\n",
        "        self.bias = torch.rand(1, dtype=torch.float64)  # Инициализация смещения случайным значением\n",
        "\n",
        "    # Функция, вычисляющая выход персептрона\n",
        "    def feed_forward(self, inputs):\n",
        "        return activation_function(torch.sum(inputs * self.weights) + self.bias)\n",
        "\n",
        "    # Функция обучения персептрона\n",
        "    def train(self, inputs, target, learning_rate=0.1):\n",
        "        output = self.feed_forward(inputs)\n",
        "        error = target - output\n",
        "\n",
        "        # Вывод входов, выходов и ошибки\n",
        "        print(f\"Входы: {inputs.tolist()} Выход: {int(output)} Ошибка: {error}\")\n",
        "\n",
        "        # Обновление весов и смещения\n",
        "        self.weights += error * inputs * learning_rate\n",
        "        self.bias += error * learning_rate\n",
        "\n",
        "# Основная функция\n",
        "if __name__ == \"__main__\":\n",
        "    # Создание персептрона с двумя входами\n",
        "    perceptron = Perceptron(2)\n",
        "\n",
        "    # Обучающие данные\n",
        "    training_inputs = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float64)\n",
        "    training_outputs = torch.tensor([0, 1, 1, 0], dtype=torch.float64)  # Логическая операция XOR\n",
        "\n",
        "    # Обучение персептрона\n",
        "    for _ in range(20000):\n",
        "        for inputs, target in zip(training_inputs, training_outputs):\n",
        "            perceptron.train(inputs, target)\n",
        "\n",
        "    # Проверка обученного персептрона\n",
        "    for inputs, target in zip(training_inputs, training_outputs):\n",
        "        output = perceptron.feed_forward(inputs)\n",
        "        print(f\"Входы: {inputs.tolist()} Выход: {int(output)}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DXlQ2qP-Cmod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. На 50 000 эпох"
      ],
      "metadata": {
        "id": "WoSdEQiGCzMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Функция активации (ступенчатая)\n",
        "def activation_function(x):\n",
        "    return torch.tensor(1.0) if x >= 0 else torch.tensor(0.0)\n",
        "\n",
        "# Класс персептрона\n",
        "class Perceptron:\n",
        "    def __init__(self, num_inputs):\n",
        "        # Инициализация весов случайными значениями\n",
        "        self.weights = torch.rand(num_inputs, dtype=torch.float64)\n",
        "        self.bias = torch.rand(1, dtype=torch.float64)  # Инициализация смещения случайным значением\n",
        "\n",
        "    # Функция, вычисляющая выход персептрона\n",
        "    def feed_forward(self, inputs):\n",
        "        return activation_function(torch.sum(inputs * self.weights) + self.bias)\n",
        "\n",
        "    # Функция обучения персептрона\n",
        "    def train(self, inputs, target, learning_rate=0.1):\n",
        "        output = self.feed_forward(inputs)\n",
        "        error = target - output\n",
        "\n",
        "        # Вывод входов, выходов и ошибки\n",
        "        print(f\"Входы: {inputs.tolist()} Выход: {int(output)} Ошибка: {error}\")\n",
        "\n",
        "        # Обновление весов и смещения\n",
        "        self.weights += error * inputs * learning_rate\n",
        "        self.bias += error * learning_rate\n",
        "\n",
        "# Основная функция\n",
        "if __name__ == \"__main__\":\n",
        "    # Создание персептрона с двумя входами\n",
        "    perceptron = Perceptron(2)\n",
        "\n",
        "    # Обучающие данные\n",
        "    training_inputs = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float64)\n",
        "    training_outputs = torch.tensor([0, 1, 1, 0], dtype=torch.float64)  # Логическая операция XOR\n",
        "\n",
        "    # Обучение персептрона\n",
        "    for _ in range(50000):\n",
        "        for inputs, target in zip(training_inputs, training_outputs):\n",
        "            perceptron.train(inputs, target)\n",
        "\n",
        "    # Проверка обученного персептрона\n",
        "    for inputs, target in zip(training_inputs, training_outputs):\n",
        "        output = perceptron.feed_forward(inputs)\n",
        "        print(f\"Входы: {inputs.tolist()} Выход: {int(output)}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FC-ItTKnC1y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Вывод"
      ],
      "metadata": {
        "id": "f3oVOAdqDIZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Однослойные персептроны** подходят для задач, которые не имеют между собой взаимосвязи и их можно разбить на части. Они могут обучаться быстро и справляться с простыми задачами, такими как логические операции OR и AND.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Многослойные персептроны** подходят для более сложных задач, для тех с которыми однослойные персептроны не могут справиться. Такие задачи требуют более сложных преобразований входных данных, что достигается за счет скрытых слоев и нелинейных функций активации. Примером такой задачи является операция XOR.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Если увеличивать количество эпох для обучения однослойного персептрона на задаче XOR, то результат все равно останется неправильным. И проблема здесь не в количестве эпох, а в структуре однослойного персептрона из-за недостатка слоев и нелинейных функций активации."
      ],
      "metadata": {
        "id": "tAnsrcOMDMwb"
      }
    }
  ]
}